{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04422e7-4916-445e-b49d-7d5cdb652cc8",
   "metadata": {},
   "source": [
    "### This file is to show an how we can convert a csv file into the tf record file, so that it can be used in the further process of pipeline. Here, we are going to see it manually but tfx provides methods to do it as well. But let's see it manually first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bb5cc3-ca1c-4763-9494-d94b1804ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46611301-3b38-4fd1-b4cd-62374fba6fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = os.path.join(os.getcwd(),\"data\",\"data.csv\")\n",
    "os.path.exists(csv_file_path)    ## to check if file is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b272e30-7d61-4b77-a864-2af8b91a5585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\atulkumarrai\\\\PycharmProjects\\\\Ineuron practice\\\\Ineuron_practice\\\\AIOps\\\\AIOps_Projects\\\\data\\\\data.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2a7bfd-be76-49bb-9011-d66e04ddd7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\atulkumarrai\\\\PycharmProjects\\\\Ineuron practice\\\\Ineuron_practice\\\\AIOps\\\\AIOps_Projects'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37383189-a2ea-431e-95ac-44e0e27fc547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('pickup_community_area', '60'), ('fare', '27.05'), ('trip_start_month', '10'), ('trip_start_hour', '2'), ('trip_start_day', '3'), ('trip_start_timestamp', '1380593700'), ('pickup_latitude', '41.836150155'), ('pickup_longitude', '-87.648787952'), ('dropoff_latitude', ''), ('dropoff_longitude', ''), ('trip_miles', '12.6'), ('pickup_census_tract', ''), ('dropoff_census_tract', ''), ('payment_type', 'Cash'), ('company', 'Taxi Affiliation Services'), ('trip_seconds', '1380'), ('dropoff_community_area', ''), ('tips', '0.0')])\n"
     ]
    }
   ],
   "source": [
    "## reading csv file\n",
    "\n",
    "with open(csv_file_path) as csv_file:\n",
    "    reader = csv.DictReader(csv_file, delimiter=\",\", quotechar='\"')     ## quotechar shows that string characters in csv are enclosed with \"\"\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888a3f24-a2f2-4ae2-868c-a8ef660c0e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'60'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[\"pickup_community_area\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388673f1-a373-47d1-9d69-83e8246ca39a",
   "metadata": {},
   "source": [
    "### Now we are able to read the csv contents, so we will create the th.writer because we need to write tf record file. We will create a separate folder for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "688da538-ec9a-455c-a92b-0ef0e6b0b577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\atulkumarrai\\\\PycharmProjects\\\\Ineuron practice\\\\Ineuron_practice\\\\AIOps\\\\AIOps_Projects\\\\tf_record_files'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_record_dir = os.path.join(os.getcwd(),\"tf_record_files\")\n",
    "tf_record_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c92ca3-8d2d-46a8-8114-ffaae58b6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let's make a directory\n",
    "os.makedirs(tf_record_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5ee5cf-46df-4dc9-a0c1-1d112c2268e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_record_file_name = os.path.join(tf_record_dir,\"data.tfrecord\")   ## This is the name of the converted file with tfrecord extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c59a9a64-1e24-4cf6-9e6b-1f888b4e6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_record_writer = tf.io.TFRecordWriter(tf_record_file_name)   ## This will create an empty tfrecord file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52ae43-de46-4a5d-a7f5-531789d0d34a",
   "metadata": {},
   "source": [
    "### We will define 3 functions, for byte conversion, int conversion and float conversion, using tf.train module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9912e24b-aba0-4113-b4ee-c1cd3b99354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _byte_feature(value):\n",
    "    value = value.encode()\n",
    "    return tf.train.BytesList(value = [value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a45e46-5b1b-42b1-ab7b-cacde59e9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Int64List(value = [value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd25a68-e783-4950-b5d1-4c336880a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.FloatList(value=[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38eabb6-e618-44b4-b226-e17bf37d2fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.example.feature_pb2.BytesList"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_byte_feature(value=\"Atul Rai\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bfb50b7-35eb-4860-b9a8-4465fe79c7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: \"Atul Rai\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_byte_feature(value=\"Atul Rai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8a5e883-0097-4733-aaa6-a60b4ca5733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: 30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_int64_feature(value=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "487c98e3-f02c-4941-82f7-7fd553f74705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.example.feature_pb2.FloatList"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_float_feature(value=34.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49631ddf-4cd3-4e14-8401-05a412275b7d",
   "metadata": {},
   "source": [
    "### Just to understand, the tf record file has 3 contents, 1)feature 2) features and 3)records. 1) Feature is the each column  2) features is the set of entire columns and 3) example means rows.  Tf record file only contains three types, byte for strings, int and float. Now let's modify our reading the csv file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7f7cc2c-228c-4440-beba-8c0e3adc204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tf.train.Example(features = tf.train.Features(feature = {\"name\": tf.train.Feature(bytes_list = _byte_feature(\"Atul Rai\"))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5588732b-2020-498e-b9d5-480b2607b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"name\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"Atul Rai\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example    ##This is one row(example) in the tf record file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08935aec-aa1d-4d11-9cb1-74c92fea1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tf.train.Example(features = tf.train.Features(feature = {\"name\": tf.train.Feature(bytes_list = _byte_feature(\"Atul Rai\")), \n",
    "                                                                  \"Age\": tf.train.Feature(int64_list = _int64_feature(24))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71e906ab-c0bd-4585-bf10-861fa6648e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"Age\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 24\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"name\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"Atul Rai\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example   ## It shows the two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e43a8a80-b047-4550-974c-f312ad81ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tf.train.Example(features = tf.train.Features(feature = {\"Name\": tf.train.Feature(bytes_list = _byte_feature(\"Atul Rai\")), \n",
    "                                                                  \"Age\": tf.train.Feature(int64_list = _int64_feature(24)),\n",
    "                                                                  \"Marks\": tf.train.Feature(float_list = _float_feature(78.8))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d56aeb22-0322-49ed-8c1f-86d6c20f5261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"Age\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 24\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"Marks\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 78.80000305175781\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"Name\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"Atul Rai\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44899ce1-2bd3-4409-9ece-33b2f6f63b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n7\\n\\x14\\n\\x04Name\\x12\\x0c\\n\\n\\n\\x08Atul Rai\\n\\x0c\\n\\x03Age\\x12\\x05\\x1a\\x03\\n\\x01\\x18\\n\\x11\\n\\x05Marks\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x9dB'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now we will serialize the example value\n",
    "example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca63cc-21f5-44de-8467-ab95b27e0258",
   "metadata": {},
   "source": [
    "#### Above byte code is how the tf record files store the data and that's why it is platform independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e96c4bc4-5dbf-42bf-a4ac-f4e198da997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's modify our functions below so that we can use them properly\n",
    "def _byte_feature(value):\n",
    "    value = value.encode()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value=[value]))\n",
    "                            \n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd2d7c93-7af6-49b5-8529-e7aaa2a3cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1 = tf.train.Example(features = tf.train.Features(feature = {\"Name\": _byte_feature(\"Atul Rai\"), \n",
    "                                                                  \"Age\": _int64_feature(24),\n",
    "                                                                  \"Marks\": _float_feature(78.8)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cf0ebb0-ce95-4083-8db6-6e1fd685b064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"Age\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 24\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"Marks\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 78.80000305175781\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"Name\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"Atul Rai\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05413aff-e85d-41cb-9135-ae252a8230bf",
   "metadata": {},
   "source": [
    "## Now let's create the tf record file using the same above method for our csv file which we have read already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3455d390-d9d5-42ec-9f36-a04e97e4871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading csv file\n",
    "\n",
    "with open(csv_file_path) as csv_file:\n",
    "    reader = csv.DictReader(csv_file, delimiter=\",\", quotechar='\"')     ## quotechar shows that string characters in csv are enclosed with \"\"\n",
    "    for row in reader:\n",
    "        feature = {\n",
    "        \"pickup_community_area\":_byte_feature(row[\"pickup_community_area\"]),\n",
    "        \"fare\": _float_feature(float(row[\"fare\"])),                     ## Since, all the values are given as string hence, converting them to float and int\n",
    "        \"trip_start_month\": _int64_feature(int(row[\"trip_start_month\"])),\n",
    "        \"trip_start_day\": _int64_feature(int(row[\"trip_start_day\"]))\n",
    "                    }\n",
    "        \n",
    "        features = tf.train.Features(feature = feature)\n",
    "        example = tf.train.Example(features = features)\n",
    "        \n",
    "        ## Now we will write into the file using serilizartion\n",
    "        tf_record_writer.write(example.SerializeToString())\n",
    "        \n",
    "tf_record_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ebbf442-cc35-4144-8125-d45fc89cb396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"fare\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 5.650000095367432\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"pickup_community_area\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"61\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"trip_start_day\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 6\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"trip_start_month\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example ## This contains the example of our csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738f8e7-9aab-4d37-9933-5aacfc5dad77",
   "metadata": {},
   "source": [
    "### We can't open the tf record file in our jupyter notebook, so we can check in our directory the tf record file will be of some considerable size. We checked and found that size of the file is more than 1.72 mb it means it has successfully converted the 4 columns into tf record file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416ab92-296c-4662-8e80-2fe36ef32a5f",
   "metadata": {},
   "source": [
    "## Now this all we can perform using csvExampleGen class of tfx at one go which we are going to see on Testing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed9449-2aeb-4fd4-adc8-130e77c1d2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
